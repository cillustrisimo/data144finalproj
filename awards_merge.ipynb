{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "415f6940-1c2f-47cf-9cde-33f30f8eaf33",
   "metadata": {},
   "source": [
    "# Merging festival_wide with IMDB awards data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5538501d-5939-4bfc-9e90-d6290796c8ab",
   "metadata": {},
   "source": [
    "# First: Getting statistics on the festival_wide dataset:\n",
    "- Documentation claims contains n=9348 unique films\n",
    "- Just checking if that is the case"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f60c882a-3072-40d2-80b1-cb037dc21524",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total Rows: 9348\n",
      "Rows with MISSING 'imdb.id': 1497\n",
      "Rows with DUPLICATE 'imdb.id': 1539\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# load festival_data\n",
    "df = pd.read_csv('1_film-dataset_festival-program_wide.csv', dtype={'imdb.id': str})\n",
    "\n",
    "# check for Empty IDs\n",
    "missing_ids = df['imdb.id'].isnull().sum()\n",
    "\n",
    "# check for Duplicate IDs\n",
    "# counts number of rows that share an ID with another row\n",
    "duplicate_ids = df.duplicated(subset=['imdb.id'], keep=False).sum()\n",
    "\n",
    "print(f\"Total Rows: {len(df)}\")\n",
    "print(f\"Rows with MISSING 'imdb.id': {missing_ids}\")\n",
    "print(f\"Rows with DUPLICATE 'imdb.id': {duplicate_ids}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7015b1ae-f06b-4171-a418-20eedda8f93d",
   "metadata": {},
   "source": [
    "- We ignore rows with missing imdb.id, and will write our script to merge our data with the awards data to account for duplicate ids by checking if a given duplicate id row is actually the same film, or a unique film (with unique uid). If unique, we also treat as missing."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b2b98901-b04b-4b04-aa0e-73c9f6b2cfce",
   "metadata": {},
   "source": [
    "# Second: Performing the merge"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "adcf62b2-580a-427c-8a60-b127722421ac",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Primary rows (Films): 9348\n",
      "Secondary rows (Awards): 106011\n",
      "21 IMDb ids shared by different movies\n",
      "Unique Films in Festival Data:   9348\n",
      "Unique Films matched with Awards:  5770\n",
      "Unique Films with no match:      3578\n",
      "Total rows in merged df:        105266\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "# set file names\n",
    "primary_file = '1_film-dataset_festival-program_wide.csv'\n",
    "secondary_file = '3_imdb-dataset_awards_long.csv'\n",
    "output_file = 'merged_film_data.csv'\n",
    "failed_ids_file = 'failed_ids.txt'\n",
    "\n",
    "# read 'imdb.id' values as string to ensure matching works correctly\n",
    "df_primary = pd.read_csv(primary_file, dtype={'imdb.id': str})\n",
    "df_secondary = pd.read_csv(secondary_file, dtype={'imdb.id': str})\n",
    "\n",
    "print(f\"Primary rows (Films): {len(df_primary)}\")\n",
    "print(f\"Secondary rows (Awards): {len(df_secondary)}\")\n",
    "\n",
    "# validate ids against unique.ids \n",
    "# if multiple rows share the same 'imdb.id' but have DIFFERENT 'unique.id's,\n",
    "# it means different movies are incorrectly sharing an imdb.id\n",
    "# thou shalt be treating these as null to prevent false matches.\n",
    "\n",
    "# filter for rows that actually have an imdb.id\n",
    "valid_ids_mask = df_primary['imdb.id'].notna()\n",
    "\n",
    "# group by imdb.id and count how many unique unique.ids share that ID\n",
    "collision_check = df_primary[valid_ids_mask].groupby('imdb.id')['unique.id'].nunique()\n",
    "\n",
    "# identify imdb.ids that map to >1 unique unique.id\n",
    "bad_ids = collision_check[collision_check > 1].index.tolist()\n",
    "\n",
    "if bad_ids:\n",
    "    # print for clariyt\n",
    "    print(f\"{len(bad_ids)} IMDb ids shared by different movies\")\n",
    "    \n",
    "    # set imdb.id to None for these conflicting rows\n",
    "    df_primary.loc[df_primary['imdb.id'].isin(bad_ids), 'imdb.id'] = np.nan\n",
    "else:\n",
    "    print(\"no id collisions found\")\n",
    "\n",
    "# merge datasets!\n",
    "# using how='left' to treat the festival program primary\n",
    "merged_df = pd.merge(\n",
    "    df_primary, \n",
    "    df_secondary, \n",
    "    on='imdb.id', \n",
    "    how='left', \n",
    "    indicator=True \n",
    ")\n",
    "\n",
    "# get stats for results\n",
    "matches_df = merged_df[merged_df['_merge'] == 'both']\n",
    "failures_df = merged_df[merged_df['_merge'] == 'left_only']\n",
    "\n",
    "# count unique festival_films matched (gets same results as unique.id)\n",
    "unique_films_matched = matches_df['imdb.id'].nunique()\n",
    "\n",
    "# checking unique.ids to count unique films failed (doing unique,id on this bc changed imdb.id to null earlier if duplicate)\n",
    "unique_films_failed = failures_df['unique.id'].nunique()\n",
    "\n",
    "total_resulting_rows = len(merged_df)\n",
    "\n",
    "print(f\"Unique Films in Festival Data:   {df_primary['unique.id'].nunique()}\")\n",
    "print(f\"Unique Films matched with Awards:  {unique_films_matched}\")\n",
    "print(f\"Unique Films with no match:      {unique_films_failed}\")\n",
    "print(f\"Total rows in merged df:        {total_resulting_rows}\")\n",
    "\n",
    "# keeping track of failures\n",
    "if unique_films_failed > 0:\n",
    "    # save the unique.id if the imdb.id is missing, otherwise the imdb.id\n",
    "    with open(failed_ids_file, 'w') as f:\n",
    "        f.write(\"unique.id,imdb.id\\n\") # Header\n",
    "        \n",
    "        # get unique pairs of unique.id/imdb.id from failures\n",
    "        failed_pairs = failures_df[['unique.id', 'imdb.id']].drop_duplicates()\n",
    "        \n",
    "        for index, row in failed_pairs.iterrows():\n",
    "            f.write(f\"{row['unique.id']},{row['imdb.id']}\\n\")\n",
    "\n",
    "# save everything\n",
    "final_df = merged_df.drop(columns=['_merge'])\n",
    "final_df.to_csv(output_file, index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11bb06d8-fea8-4d81-814c-fef046be8eef",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
